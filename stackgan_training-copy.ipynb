{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404d022b",
   "metadata": {},
   "source": [
    "Synthesizing high-quality images from text descriptions\n",
    "Implementation of \"Stage 1 \" of StackGAN\n",
    "Stage I of StackGAN\n",
    "1- takes input as text,\n",
    "2- convert the text to embedding using our pre-trained character level embedding.\n",
    "3- Then, we give this embedding to Conditional Augmentation (CA) and\n",
    "4- then to Stage I Generator which gives us low-resolution 64*64 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937592b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp311-cp311-win_amd64.whl (272.9 MB)\n",
      "     -------------------------------------- 272.9/272.9 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ------------------------------------ 126.5/126.5 kB 573.0 kB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.8-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.9.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 2.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.0-cp310-abi3-win_amd64.whl (422 kB)\n",
      "     -------------------------------------- 422.5/422.5 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1.tar.gz (50 kB)\n",
      "     ---------------------------------------- 50.9/50.9 kB 1.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.0-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.1.0-cp311-cp311-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.7/120.7 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "     -------------------------------------- 178.2/178.2 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.9/93.9 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "     -------------------------------------- 242.5/242.5 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.3/181.3 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.9/83.9 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 2.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.9-py3-none-any.whl size=1477827 sha256=23ef91d7d3e541afb13dd0a55586bf14c7652accd04a905c5b6fa28ba35bd87f\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\5f\\0f\\08\\2c7764ea8dde2dde5e512d6a90a5a6ab2c7b9a45dac83fade5\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, jax, astunparse, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Running setup.py install for wrapt: started\n",
      "  Running setup.py install for wrapt: finished with status 'done'\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.5.8 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 h5py-3.8.0 jax-0.4.9 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-2.3.4 wheel-0.40.0 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: wrapt is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98738b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"StackGAN.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4dfdd",
   "metadata": {},
   "source": [
    "# ############################################################\n",
    "\n",
    "Conditioning Augmentation Network\n",
    "############################################################\n",
    "\n",
    "Computer doesn’t understand words, but it can represent the words in terms of something it does “understand”. That’s the “text embedding”, and it’s used as the c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcc6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditioned by the text.\n",
    "def conditioning_augmentation(x):\n",
    "\t\"\"\"The mean_logsigma passed as argument is converted into the text conditioning variable.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The output of the text embedding passed through a FC layer with LeakyReLU non-linearity.\n",
    "\n",
    "\tReturns:\n",
    "\t \tc: The text conditioning variable after computation.\n",
    "\t\"\"\"\n",
    "\tmean = x[:, :128]\n",
    "\tlog_sigma = x[:, 128:]\n",
    "\n",
    "\tstddev = tf.math.exp(log_sigma)\n",
    "\tepsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n",
    "\tc = mean + stddev * epsilon\n",
    "\treturn c\n",
    "\n",
    "def build_ca_network():\n",
    "\t\"\"\"Builds the conditioning augmentation network.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,)) #size of the vocabulary in the text data\n",
    "\tmls = Dense(256)(input_layer1)\n",
    "\tmls = LeakyReLU(alpha=0.2)(mls)\n",
    "\tca = Lambda(conditioning_augmentation)(mls)\n",
    "\treturn Model(inputs=[input_layer1], outputs=[ca]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52266d",
   "metadata": {},
   "source": [
    "############################################################\n",
    "\n",
    "Stage 1 Generator Network\n",
    "The generator is fed with the text captions in the form of Embedding vectors which will be used to condition its generation of features.\n",
    "A vector with random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9cccfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpSamplingBlock(x, num_kernels):\n",
    "\t\"\"\"An Upsample block with Upsampling2D, Conv2D, BatchNormalization and a ReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the Upsampling block.\n",
    "\t\"\"\"\n",
    "\tx = UpSampling2D(size=(2,2))(x)\n",
    "\tx = Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x) #prevent from mode collapse\n",
    "\tx = ReLU()(x)\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_stage1_generator():\n",
    "\n",
    "\tinput_layer1 = Input(shape=(1024,))\n",
    "\tca = Dense(256)(input_layer1)\n",
    "\tca = LeakyReLU(alpha=0.2)(ca)\n",
    "\n",
    "\t# Obtain the conditioned text\n",
    "\tc = Lambda(conditioning_augmentation)(ca)\n",
    "\n",
    "\tinput_layer2 = Input(shape=(100,))\n",
    "\tconcat = Concatenate(axis=1)([c, input_layer2]) \n",
    "\n",
    "\tx = Dense(16384, use_bias=False)(concat) \n",
    "\tx = ReLU()(x)\n",
    "\tx = Reshape((4, 4, 1024), input_shape=(16384,))(x)\n",
    "\n",
    "\tx = UpSamplingBlock(x, 512) \n",
    "\tx = UpSamplingBlock(x, 256)\n",
    "\tx = UpSamplingBlock(x, 128)\n",
    "\tx = UpSamplingBlock(x, 64)   # upsampled our image to 64*64*3 \n",
    "\n",
    "\tx = Conv2D(3, kernel_size=3, padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = Activation('tanh')(x)\n",
    "\n",
    "\tstage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, ca]) \n",
    "\treturn stage1_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21091e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          262400      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128)          0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 228)          0           ['lambda[0][0]',                 \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16384)        3735552     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 16384)        0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 4, 4, 1024)   0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 8, 8, 1024)   0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 8, 512)    4718592     ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 8, 8, 512)   2048        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 8, 8, 512)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0          ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 256)  1179648     ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0          ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 128)  294912      ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0          ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 64)   73728       ['up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 3)    1728        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 64, 3)    0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,270,400\n",
      "Trainable params: 10,268,480\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_stage1_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0547ab",
   "metadata": {},
   "source": [
    "############################################################\n",
    "\n",
    "Stage 1 Discriminator Network\n",
    "############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dfe3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(x, num_kernels, kernel_size=(4,4), strides=2, activation=True):\n",
    "\t\"\"\"A ConvBlock with a Conv2D, BatchNormalization and LeakyReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the ConvBlock block.\n",
    "\t\"\"\"\n",
    "\tx = Conv2D(num_kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\t\n",
    "\tif activation:\n",
    "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_embedding_compressor():\n",
    "    \"\"\"Build embedding compressor model\n",
    "    \"\"\"\n",
    "    input_layer1 = Input(shape=(1024,)) \n",
    "    x = Dense(128)(input_layer1)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer1], outputs=[x])\n",
    "    return model\n",
    "\n",
    "# the discriminator is fed with two inputs, the feature from Generator and the text embedding\n",
    "def build_stage1_discriminator():\n",
    "\t\"\"\"Builds the Stage 1 Discriminator that uses the 64x64 resolution images from the generator\n",
    "\tand the compressed and spatially replicated embedding.\n",
    "\n",
    "\tReturns:\n",
    "\t\tStage 1 Discriminator Model for StackGAN.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(64, 64, 3))  \n",
    "\n",
    "\tx = Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\tx = ConvBlock(x, 128)\n",
    "\tx = ConvBlock(x, 256)\n",
    "\tx = ConvBlock(x, 512)\n",
    "\n",
    "\t# Obtain the compressed and spatially replicated text embedding\n",
    "\tinput_layer2 = Input(shape=(4, 4, 128)) #2nd input to discriminator, text embedding\n",
    "\tconcat = concatenate([x, input_layer2])\n",
    "\n",
    "\tx1 = Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(concat)\n",
    "\tx1 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx1 = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\t# Flatten and add a FC layer to predict.\n",
    "\tx1 = Flatten()(x1)\n",
    "\tx1 = Dense(1)(x1)\n",
    "\tx1 = Activation('sigmoid')(x1)\n",
    "\n",
    "\tstage1_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x1])  \n",
    "\treturn stage1_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef222a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 64)   3072        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 64)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  131072      ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 256)    524288      ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 512)    2097152     ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 512)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 4, 4, 512)    0           ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8192)         0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            8193        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,767,361\n",
      "Trainable params: 2,765,569\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_stage1_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe251e17",
   "metadata": {},
   "source": [
    "############################################################\n",
    "\n",
    "Stage 1 Adversarial Model (Building a GAN)\n",
    "############################################################\n",
    "\n",
    "Generator and discriminator are stacked together. Output of the former is the input of the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226672f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building GAN with Generator and Discriminator\n",
    "\n",
    "def build_adversarial(generator_model, discriminator_model):\n",
    "\t\"\"\"Stage 1 Adversarial model.\n",
    "\n",
    "\tArgs:\n",
    "\t\tgenerator_model: Stage 1 Generator Model\n",
    "\t\tdiscriminator_model: Stage 1 Discriminator Model\n",
    "\n",
    "\tReturns:\n",
    "\t\tAdversarial Model.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,))  \n",
    "\tinput_layer2 = Input(shape=(100,)) \n",
    "\tinput_layer3 = Input(shape=(4, 4, 128)) \n",
    "\n",
    "\tx, ca = generator_model([input_layer1, input_layer2]) #text,noise\n",
    "\n",
    "\tdiscriminator_model.trainable = False \n",
    "\n",
    "\tprobabilities = discriminator_model([x, input_layer3]) \n",
    "\tadversarial_model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[probabilities, ca])\n",
    "\treturn adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4322d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 64, 64, 3),  10270400    ['input_5[0][0]',                \n",
      "                                 (None, 256)]                     'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 1)            2767361     ['model[0][0]',                  \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,037,761\n",
      "Trainable params: 10,268,480\n",
      "Non-trainable params: 2,769,281\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ganstage1 = build_adversarial(generator, discriminator)\n",
    "ganstage1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fb011",
   "metadata": {},
   "source": [
    "############################################################\n",
    "\n",
    "Train Utilities\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ef10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_prefix():\n",
    "\tcheckpoint_dir = './training_checkpoints'\n",
    "\tcheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "\n",
    "\treturn checkpoint_prefix\n",
    "\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "\tmean = y_pred[:, :128]\n",
    "\tls = y_pred[:, 128:]\n",
    "\tloss = -ls + 0.5 * (-1 + tf.math.exp(2.0 * ls) + tf.math.square(mean))\n",
    "\tloss = K.mean(loss)\n",
    "\treturn loss\n",
    "\n",
    "def normalize(input_image, real_image):\n",
    "\tinput_image = (input_image / 127.5) - 1\n",
    "\treal_image = (real_image / 127.5) - 1\n",
    "\n",
    "\treturn input_image, real_image\n",
    "\n",
    "def load_class_ids_filenames(class_id_path, filename_path):\n",
    "\twith open(class_id_path, 'rb') as file:\n",
    "\t\tclass_id = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\twith open(filename_path, 'rb') as file:\n",
    "\t\tfilename = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\treturn class_id, filename\n",
    "\n",
    "def load_text_embeddings(text_embeddings):\n",
    "\twith open(text_embeddings, 'rb') as file:\n",
    "\t\tembeds = pickle.load(file, encoding='latin1')\n",
    "\t\tembeds = np.array(embeds)\n",
    "\n",
    "\treturn embeds\n",
    "\n",
    "def load_bbox(data_path):\n",
    "\tbbox_path = data_path + '/bounding_boxes.txt'\n",
    "\timage_path = data_path + '/images.txt'\n",
    "\tbbox_df = pd.read_csv(bbox_path, delim_whitespace=True, header=None).astype(int)\n",
    "\tfilename_df = pd.read_csv(image_path, delim_whitespace=True, header=None)\n",
    "\n",
    "\tfilenames = filename_df[1].tolist()\n",
    "\tbbox_dict = {i[:-4]:[] for i in filenames[:2]}\n",
    "\n",
    "\tfor i in range(0, len(filenames)):\n",
    "\t\tbbox = bbox_df.iloc[i][1:].tolist()\n",
    "\t\tdict_key = filenames[i][:-4]\n",
    "\t\tbbox_dict[dict_key] = bbox\n",
    "\n",
    "\treturn bbox_dict\n",
    "\n",
    "def load_images(image_path, bounding_box, size):\n",
    "\t\"\"\"Crops the image to the bounding box and then resizes it.\n",
    "\t\"\"\"\n",
    "\timage = Image.open(image_path).convert('RGB')\n",
    "\tw, h = image.size\n",
    "\tif bounding_box is not None:\n",
    "\t\tr = int(np.maximum(bounding_box[2], bounding_box[3]) * 0.75)\n",
    "\t\tc_x = int((bounding_box[0] + bounding_box[2]) / 2)\n",
    "\t\tc_y = int((bounding_box[1] + bounding_box[3]) / 2)\n",
    "\t\ty1 = np.maximum(0, c_y - r)\n",
    "\t\ty2 = np.minimum(h, c_y + r)\n",
    "\t\tx1 = np.maximum(0, c_x - r)\n",
    "\t\tx2 = np.minimum(w, c_x + r)\n",
    "\t\timage = image.crop([x1, y1, x2, y2])\n",
    "\n",
    "\timage = image.resize(size, PIL.Image.BILINEAR)\n",
    "\treturn image\n",
    "\n",
    "def load_data(filename_path, class_id_path, dataset_path, embeddings_path, size):\n",
    "\t\"\"\"Loads the Dataset.\n",
    "\t\"\"\"\n",
    "\tdata_dir = (r\"C:\\Users\\HP\\Desktop\\arshi programs\\birds_implementation\\birds\")\n",
    "\ttrain_dir = data_dir + \"/train\"\n",
    "\ttest_dir = data_dir + \"/test\"\n",
    "\tembeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tembeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tfilename_path_train = train_dir + \"/filenames.pickle\"\n",
    "\tfilename_path_test = test_dir + \"/filenames.pickle\"\n",
    "\tclass_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "\tclass_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "\tdataset_path = (r\"C:\\Users\\HP\\Desktop\\arshi programs\\birds_implementation\\CUB_200_2011\")\n",
    "\tclass_id, filenames = load_class_ids_filenames(class_id_path, filename_path)\n",
    "\tembeddings = load_text_embeddings(embeddings_path)\n",
    "\tbbox_dict = load_bbox(dataset_path)\n",
    "\n",
    "\tx, y, embeds = [], [], []\n",
    "\n",
    "\tfor i, filename in enumerate(filenames):\n",
    "\t\tbbox = bbox_dict[filename]\n",
    "\n",
    "\t\ttry:\t\n",
    "\t\t\timage_path = f'{dataset_path}/images/{filename}.jpg'\n",
    "\t\t\timage = load_images(image_path, bbox, size)\n",
    "\t\t\te = embeddings[i, :, :]\n",
    "\t\t\tembed_index = np.random.randint(0, e.shape[0] - 1)\n",
    "\t\t\tembed = e[embed_index, :]\n",
    "\n",
    "\t\t\tx.append(np.array(image))\n",
    "\t\t\ty.append(class_id[i])\n",
    "\t\t\tembeds.append(embed)\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f'{e}')\n",
    "\t\n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\tembeds = np.array(embeds)\n",
    "\t\n",
    "\treturn x, y, embeds\n",
    "\n",
    "def save_image(file, save_path):\n",
    "\t\"\"\"Saves the image at the specified file path.\n",
    "\t\"\"\"\n",
    "\timage = plt.figure()\n",
    "\tax = image.add_subplot(1,1,1)\n",
    "\tax.imshow(file)\n",
    "\tax.axis(\"off\")\n",
    "\tplt.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d375e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb13e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# StackGAN class\n",
    "############################################################\n",
    "\n",
    "class StackGanStage1(object):\n",
    "  \"\"\"StackGAN Stage 1 class.\"\"\"\n",
    "\n",
    "  data_dir = (r\"C:\\Users\\HP\\Desktop\\arshi programs\\birds_implementation\\birds\")\n",
    "  train_dir = data_dir + \"/train\"\n",
    "  test_dir = data_dir + \"/test\"\n",
    "  embeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "  embeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "  filename_path_train = train_dir + \"/filenames.pickle\"\n",
    "  filename_path_test = test_dir + \"/filenames.pickle\"\n",
    "  class_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "  class_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "  dataset_path = (r\"C:\\Users\\HP\\Desktop\\arshi programs\\birds_implementation\\CUB_200_2011\")\n",
    "  def __init__(self, epochs=500, z_dim=100, batch_size=64, enable_function=True, stage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
    "\t  self.epochs = epochs\n",
    "\t  self.z_dim = z_dim\n",
    "\t  self.enable_function = enable_function\n",
    "\t  self.stage1_generator_lr = stage1_generator_lr\n",
    "\t  self.stage1_discriminator_lr = stage1_discriminator_lr\n",
    "\t  self.image_size = 64\n",
    "\t  self.conditioning_dim = 128\n",
    "\t  self.batch_size = batch_size\n",
    "        \n",
    "\t  self.stage1_generator_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t  self.stage1_discriminator_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "        \n",
    "\t  self.stage1_generator = build_stage1_generator()\n",
    "\t  self.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t  self.stage1_discriminator = build_stage1_discriminator()\n",
    "\t  self.stage1_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage1_discriminator_optimizer)\n",
    "\n",
    "\t  self.ca_network = build_ca_network()\n",
    "\t  self.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t  self.embedding_compressor = build_embedding_compressor()\n",
    "\t  self.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t  self.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
    "\t  self.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t  self.checkpoint1 = tf.train.Checkpoint(\n",
    "        \tgenerator_optimizer=self.stage1_generator_optimizer,\n",
    "        \tdiscriminator_optimizer=self.stage1_discriminator_optimizer,\n",
    "        \tgenerator=self.stage1_generator,\n",
    "        \tdiscriminator=self.stage1_discriminator)\n",
    "\n",
    "  def visualize_stage1(self):\n",
    "\t  \"\"\"Running Tensorboard visualizations.\n",
    "\t\t\"\"\"\n",
    "\t  tb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "\t  tb.set_model(self.stage1_generator)\n",
    "\t  tb.set_model(self.stage1_discriminator)\n",
    "\t  tb.set_model(self.ca_network)\n",
    "\t  tb.set_model(self.embedding_compressor)\n",
    "\n",
    "  def train_stage1(self):\n",
    "\t  \"\"\"Trains the stage1 StackGAN.\n",
    "    \"\"\"\n",
    "\t  x_train, y_train, train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
    "\n",
    "\t  x_test, y_test, test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
    "\n",
    "\t  real = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
    "\t  fake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
    "\n",
    "\t  for epoch in range(self.epochs):\n",
    "\t\t  print(f'Epoch: {epoch}')\n",
    "\n",
    "\t\t  gen_loss = []\n",
    "\t\t  dis_loss = []\n",
    "\n",
    "\t\t  num_batches = int(x_train.shape[0] / self.batch_size)\n",
    "\n",
    "\t\t  for i in range(num_batches):\n",
    "\n",
    "\t\t    latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t    embedding_text = train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\t\t    compressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
    "\t\t    compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
    "\t\t    compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "\t\t    image_batch = x_train[i * self.batch_size:(i+1) * self.batch_size]\n",
    "\t\t    image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "\t\t    gen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
    "\n",
    "\t\t    discriminator_loss = self.stage1_discriminator.train_on_batch([image_batch, compressed_embedding], \n",
    "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
    "\n",
    "\t\t    discriminator_loss_gen = self.stage1_discriminator.train_on_batch([gen_images, compressed_embedding],\n",
    "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
    "\n",
    "\t\t    discriminator_loss_wrong = self.stage1_discriminator.train_on_batch([gen_images[: self.batch_size-1], compressed_embedding[1:]], \n",
    "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size-1, 1)))\n",
    "\n",
    "\t\t    # Discriminator loss\n",
    "\t\t    d_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_wrong))\n",
    "\t\t    dis_loss.append(d_loss)\n",
    "\n",
    "\t\t    print(f'Discriminator Loss: {d_loss}')\n",
    "\n",
    "\t\t    # Generator loss\n",
    "\t\t    g_loss = self.stage1_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
    "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
    "\n",
    "\t\t    print(f'Generator Loss: {g_loss}')\n",
    "\t\t    gen_loss.append(g_loss)\n",
    "\n",
    "\t\t    if epoch % 5 == 0:\n",
    "\t\t\t\t    latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\t    embedding_batch = test_embeds[0 : self.batch_size]\n",
    "\t\t\t\t    gen_images, _ = self.stage1_generator.predict_on_batch([embedding_batch, latent_space])\n",
    "\n",
    "\t\t\t\t    for i, image in enumerate(gen_images[:10]):\n",
    "\t\t\t\t        save_image(image, f'test/gen_1_{epoch}_{i}')\n",
    "\n",
    "\t\t    if epoch % 25 == 0:\n",
    "\t\t      self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t\t      self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")\n",
    "\t\t      self.ca_network.save_weights('weights/stage1_ca.h5')\n",
    "\t\t      self.embedding_compressor.save_weights('weights/stage1_embco.h5')\n",
    "\t\t      self.stage1_adversarial.save_weights('weights/stage1_adv.h5')      \n",
    "\n",
    "\t  self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t  self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f89098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'build_stage1_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stage1 \u001b[38;5;241m=\u001b[39m \u001b[43mStackGanStage1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m stage1\u001b[38;5;241m.\u001b[39mtrain_stage1()\n",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m, in \u001b[0;36mStackGanStage1.__init__\u001b[1;34m(self, epochs, z_dim, batch_size, enable_function, stage1_generator_lr, stage1_discriminator_lr)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1_generator_optimizer \u001b[38;5;241m=\u001b[39m Adam(lr\u001b[38;5;241m=\u001b[39mstage1_generator_lr, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1_discriminator_optimizer \u001b[38;5;241m=\u001b[39m Adam(lr\u001b[38;5;241m=\u001b[39mstage1_discriminator_lr, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1_generator \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_stage1_generator\u001b[49m()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1_generator\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1_generator_optimizer)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1_discriminator \u001b[38;5;241m=\u001b[39m build_stage1_discriminator()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_stage1_generator' is not defined"
     ]
    }
   ],
   "source": [
    "stage1 = StackGanStage1()\n",
    "stage1.train_stage1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a6523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
